ğŸ”µ PHASE 1: Engine Startup (BaÅŸlangÄ±Ã§)
1ï¸âƒ£ startEngine(flowId)
Ne Yapar:
- Transfer workflow'unun baÅŸlangÄ±Ã§ noktasÄ±
- Scheduler (cron job) tarafÄ±ndan otomatik tetiklenir
- Ã–rnek cron: "0 * * * * *" (her saat baÅŸÄ±)

Detay:
- flowId Ã¶rnek: 111 (VF_TR_D_HW_ENB-PM)
- ExecutorService thread pool'larÄ± oluÅŸturur
- Log dosyasÄ±na baÅŸlangÄ±Ã§ kaydÄ± yazar
- JVM heap memory check yapar

GerÃ§ek KullanÄ±m:
Scheduler â†’ 10:00:00 â†’ startEngine(flowId=111) Ã§aÄŸrÄ±sÄ±

2ï¸âƒ£ Repository.findConnections(flowId)
Ne Yapar:
Bu flow'a ait tÃ¼m aktif connection'larÄ± database'den yÃ¼kler

SQL Query:
SELECT * FROM t_connection 
WHERE flow_id = 111 
  AND is_active = true

DÃ¶nen Data (Ã–rnek):
[
  {id: 1111, server_id: 2, path_id: 117, last_modified_time: "2024-07-07 16:01:53"},
  {id: 1112, server_id: 2, path_id: 118, last_modified_time: "2024-07-07 16:01:53"},
  {id: 1113, server_id: 2, path_id: 119, last_modified_time: "2024-07-07 16:01:53"}
]

Her Connection Nedir:
- server_id: Hangi SFTP server (IP, port, credentials)
- path_id: Hangi remote path (/export/home/omc/var/fileint/pmneexport/)
- last_modified_time: Son transfer edilen dosyanÄ±n tarihi (incremental iÃ§in)

SonuÃ§:
3 connection â†’ 3 Handler thread yaratÄ±lacak (parallel)

3ï¸âƒ£ Repository.getEngineConfig(flowId)
Ne Yapar:
Bu flow iÃ§in hangi adÄ±mlarÄ±n Ã§alÄ±ÅŸacaÄŸÄ±nÄ± belirleyen konfigÃ¼rasyonu yÃ¼kler

SQL Query:
SELECT * FROM t_transfer_engine 
WHERE flow_id = 111

DÃ¶nen Data (Ã–rnek):
{
  flow_id: 111,
  pre_transfer: true,
  on_transfer: true,
  decompress: true,           â† .gz dosyalarÄ±nÄ± aÃ§
  validation: true,            â† XML'leri XSD ile validate et
  post_transfer: true,
  on_transfer_thread_count: 8, â† KaÃ§ tane handler parallel Ã§alÄ±ÅŸsÄ±n
  decompress_thread_count: 8,
  validation_thread_count: 8
}

Bu Flags Ne Ä°ÅŸe Yarar:
- decompress=false â†’ .gz dosyalarÄ± olduÄŸu gibi bÄ±rakÄ±lÄ±r
- validation=false â†’ XML validation atlanÄ±r (daha hÄ±zlÄ±)
- Thread counts â†’ Performance tuning iÃ§in

4ï¸âƒ£ preparePaths()
Ne Yapar:
DosyalarÄ±n indirileceÄŸi, iÅŸleneceÄŸi klasÃ¶rleri oluÅŸturur

OluÅŸturulan KlasÃ¶rler:
/data/transfer/HW_ENB_PM_TRANSFER/20240708/raw/
/data/transfer/HW_ENB_PM_TRANSFER/20240708/processed/
/data/transfer/HW_ENB_PM_TRANSFER/20240708/archive/

Detay:
- component: HW_ENB_PM_TRANSFER (t_transfer_component tablosundan)
- date: 20240708 (bugÃ¼nÃ¼n tarihi)
- EÄŸer klasÃ¶r varsa â†’ skip (hata vermez)
- EÄŸer disk doluysa â†’ Exception throw eder

Neden Gerekli:
Her gÃ¼nÃ¼n dosyalarÄ± ayrÄ± klasÃ¶rlerde tutulur
Ã–rnek: 1 haftalÄ±k veri = 7 klasÃ¶r (retention policy)

5ï¸âƒ£ For Each Connection: Create Handler
Ne Yapar:
Her connection iÃ§in bir Handler thread yaratÄ±r ve parallel Ã§alÄ±ÅŸtÄ±rÄ±r

Kod MantÄ±ÄŸÄ±:
ExecutorService executor = Executors.newFixedThreadPool(8);
for (Connection conn : connections) {
    TransferBaseHandler handler = new TransferBaseHandler(conn);
    executor.submit(handler); // Async Ã§alÄ±ÅŸtÄ±r
}

Ã–rnek:
3 connection â†’ 3 Handler thread
Thread-1: eNodeB_001 iÃ§in transfer
Thread-2: eNodeB_002 iÃ§in transfer  
Thread-3: eNodeB_003 iÃ§in transfer

Her Ã¼Ã§Ã¼ AYNI ANDA Ã§alÄ±ÅŸÄ±r (parallel)

Performance:
Sequential: 3 Ã— 10 dakika = 30 dakika
Parallel: MAX(10, 10, 10) = 10 dakika âœ…

ğŸŸ¢ PHASE 2: Handler Workflow (Her Connection Ä°Ã§in)
6ï¸âƒ£ run()
Ne Yapar:
Handler thread'in ana metodu (Runnable interface)

Kod:
public void run() {
    try {
        // TÃ¼m iÅŸlemler burada
    } catch (Exception e) {
        log.error("Handler failed", e);
        // DEVAM ET (diÄŸer handler'lar etkilenmez)
    }
}

Ã–nemli:
Bir handler hata verse bile diÄŸerleri Ã§alÄ±ÅŸmaya devam eder
Ã–rnek: eNodeB_001 baÄŸlantÄ± hatasÄ± â†’ eNodeB_002 ve 003 etkilenmez

7ï¸âƒ£ ConnectionFactory.connect(server, path)
Ne Yapar:
Uzak SFTP/FTP sunucusuna baÄŸlanÄ±r

Server Bilgisi (t_server tablosundan):
{
  id: 2,
  ip: "192.168.0.180",
  port: 22,
  username: "ttg",
  password: "ttgttg",
  protocol: "SFTP"
}

BaÄŸlantÄ± SÃ¼reci:
1. TCP socket aÃ§ (192.168.0.180:22)
2. SSH handshake
3. Authentication (username/password)
4. SFTP session baÅŸlat
5. Change directory â†’ /export/home/omc/var/fileint/pmneexport/

Timeout:
30 saniye iÃ§inde baÄŸlanamazsa â†’ ConnectionException

Hata DurumlarÄ±:
- Wrong password â†’ Authentication failed
- Network down â†’ Connection timeout
- Server kapalÄ± â†’ Connection refused

Bu durumda:
â†’ disconnect() Ã§aÄŸrÄ±lÄ±r
â†’ Handler sonlanÄ±r (diÄŸerleri devam eder)
â†’ Database'e kayÄ±t YAPILMAZ (failed connection)

8ï¸âƒ£ Repository.getLastModifiedTime(connectionId)
Ne Yapar:
Son transfer edilen dosyanÄ±n tarihini database'den okur

SQL Query:
SELECT last_modified_time 
FROM t_connection 
WHERE id = 1111

DÃ¶nen DeÄŸer:
"2024-07-07 16:01:53.736"

Bu Ne Ä°ÅŸe Yarar (CRITICAL):
Incremental Transfer MantÄ±ÄŸÄ±:
- Ä°lk Ã§alÄ±ÅŸma: last_modified_time = NULL â†’ TÃœM DOSYALAR indirilir
- 2. Ã§alÄ±ÅŸma: last_modified_time = "2024-07-07 16:01:53" 
  â†’ SADECE bu tarihten SONRAKI dosyalar indirilir

Performance KazancÄ±:
Ä°lk Ã§alÄ±ÅŸma: 100,000 dosya indir (10 saat)
2. Ã§alÄ±ÅŸma: 1,000 yeni dosya indir (6 dakika) âœ…

Ã–rnekle:
BugÃ¼n saat 10:00'da Ã§alÄ±ÅŸtÄ± â†’ 1000 dosya indirdi
BugÃ¼n saat 11:00'da Ã§alÄ±ÅŸtÄ± â†’ Sadece 10:00'dan sonraki dosyalar (50 dosya)

9ï¸âƒ£ ConnectionFactory.listFiles(path)
Ne Yapar:
Remote server'daki dosya listesini okur

SFTP Command:
ls -la /export/home/omc/var/fileint/pmneexport/

DÃ¶nen Data (Ã–rnek):
[
  {name: "A20240708.0000+0300-0100+0300_eNodeB_001.xml.gz", 
   size: 15728640, 
   modifiedTime: "2024-07-08 00:15:00"},
  
  {name: "A20240708.0100+0300-0200+0300_eNodeB_001.xml.gz",
   size: 16234567,
   modifiedTime: "2024-07-08 01:15:00"},
  
  ... (10,000+ dosya)
]

Recursive Scan:
EÄŸer path_walk_method = "NESTED" ise:
/pmneexport/
  â”œâ”€â”€ neexport_20240708/
  â”‚   â”œâ”€â”€ eNodeB_001/
  â”‚   â””â”€â”€ eNodeB_002/
  â””â”€â”€ neexport_20240709/

TÃ¼m subdirectory'leri tarar

Performance:
10,000 dosya listesi â†’ 2-3 saniye (SFTP optimize edilmiÅŸ)

ğŸ”Ÿ filterFiles(lastModifiedTime)
Ne Yapar:
Sadece yeni/deÄŸiÅŸmiÅŸ dosyalarÄ± seÃ§er

Filter MantÄ±ÄŸÄ±:
List<File> filtered = new ArrayList<>();
for (File f : allFiles) {
    if (f.modifiedTime > lastModifiedTime) {  // â† CORE LOGIC
        filtered.add(f);
    }
}

Ã–rnek:
lastModifiedTime = "2024-07-07 16:01:53"

TÃ¼m Dosyalar (10,000):
âŒ A20240707.1500+0300_eNodeB_001.xml.gz â†’ modifiedTime: 2024-07-07 15:30:00 (ESKÄ°)
âŒ A20240707.1530+0300_eNodeB_001.xml.gz â†’ modifiedTime: 2024-07-07 16:00:00 (ESKÄ°)
âœ… A20240707.1600+0300_eNodeB_001.xml.gz â†’ modifiedTime: 2024-07-07 16:15:00 (YENÄ°)
âœ… A20240708.0000+0300_eNodeB_001.xml.gz â†’ modifiedTime: 2024-07-08 00:15:00 (YENÄ°)

Filtered List: 2 dosya (10,000'den sadece 2 tanesi)

Ek Filtreler:
- File size > 0 bytes (boÅŸ dosyalar hariÃ§)
- Extension: .xml.gz, .zip (sadece bunlar)
- transfer_try_count < 10 (10 kez denenmiÅŸse artÄ±k deneme)

Delta Transfer:
10,000 dosya â†’ 50 dosya filter sonrasÄ±
Transfer time: 10 saat â†’ 5 dakika âœ…

1ï¸âƒ£1ï¸âƒ£ ConnectionFactory.downloadFile()
Ne Yapar:
DosyalarÄ± fiziksel olarak remote'dan local'e indirir

SFTP GET Command:
for (File file : filteredFiles) {
    sftp.get(remoteFile, localFile);
}

Ã–rnek:
Remote: /pmneexport/A20240708.0000+0300_eNodeB_001.xml.gz
Local:  /data/transfer/HW_ENB_PM/20240708/raw/A20240708.0000+0300_eNodeB_001.xml.gz

Transfer DetaylarÄ±:
- Protocol: SFTP (SSH over FTP)
- Mode: Binary (not text)
- Buffer: 64KB chunks (her seferinde 64KB okur/yazar)
- Progress: 0% â†’ 25% â†’ 50% â†’ 75% â†’ 100%

Retry Mechanism:
Attempt 1: Transfer baÅŸladÄ± â†’ Network error â†’ RETRY
Attempt 2: 50% indirdi â†’ Connection lost â†’ RETRY (kaldÄ±ÄŸÄ± yerden devam)
Attempt 3: 100% â†’ SUCCESS âœ…

Max retry: 10 (configurable)
10 attempt sonra: Skip dosyayÄ±, devam et

Performance:
Network speed: 100 Mbps
File size: 15 MB
Transfer time: 15 Ã— 8 / 100 = 1.2 saniye

50 dosya Ã— 1.2 saniye = 60 saniye (1 dakika)

Real-world Files:
Huawei eNodeB PM: 1-50MB (compressed XML)
Huawei eNodeB CM: 100KB-5MB (configuration)

1ï¸âƒ£2ï¸âƒ£ Repository.saveResults(fileList)
Ne Yapar:
Ä°ndirilen dosyalarÄ±n metadata'sÄ±nÄ± database'e kaydeder

Bulk Insert (1000 record at once):
INSERT INTO t_transfer_connection_result 
(file_id, remote_file_name, is_downloaded, file_size, 
 transfer_try_count, file_modified_time, file_transfer_time,
 source_node_name, fragment_time, connection_id)
VALUES
  ('20240708000001', 'A20240708.0000+0300_eNodeB_001.xml.gz', true, 15728640, 
   1, '2024-07-08 00:15:00', '2024-07-08 10:05:32', 'eNodeB_001', 
   '2024-07-08 00:00:00', 1111),
  
  ('20240708000002', 'A20240708.0100+0300_eNodeB_001.xml.gz', true, 16234567,
   1, '2024-07-08 01:15:00', '2024-07-08 10:05:34', 'eNodeB_001',
   '2024-07-08 01:00:00', 1111),
  
  ... (1000 records)

Transaction:
BEGIN TRANSACTION
  INSERT 1000 records
  IF SUCCESS â†’ COMMIT
  IF ERROR â†’ ROLLBACK (hiÃ§bir kayÄ±t yazÄ±lmaz)
END TRANSACTION

Neden Bulk Insert:
Tek tek insert: 1000 Ã— 10ms = 10 saniye
Bulk insert: 1 Ã— 100ms = 0.1 saniye âœ… (100x hÄ±zlÄ±)

Bu Tablo Ne Ä°ÅŸe Yarar:
- Transfer history (audit trail)
- Debugging (hangi dosya ne zaman indirildi)
- Monitoring (toplam dosya sayÄ±sÄ±, success rate)
- Retry logic (transfer_try_count)

Table Size:
9.1MB (largest table in Transfer module)
Millions of records over time

1ï¸âƒ£3ï¸âƒ£ Repository.updateLastModifiedTime()
Ne Yapar:
Connection'Ä±n last_modified_time'Ä±nÄ± gÃ¼nceller (next run iÃ§in)

Calculation:
maxModifiedTime = MAX(file.modifiedTime) from downloaded files
maxModifiedTime = "2024-07-08 03:30:00"

SQL Update:
UPDATE t_connection 
SET last_modified_time = '2024-07-08 03:30:00'
WHERE id = 1111

Ã–nce:
last_modified_time = "2024-07-07 16:01:53.736"

Sonra:
last_modified_time = "2024-07-08 03:30:00.000"

Bir Sonraki Ã‡alÄ±ÅŸma (1 saat sonra):
filterFiles() â†’ Sadece "2024-07-08 03:30:00"'dan SONRAKÄ° dosyalar

Bu CRITICAL Ã§Ã¼nkÃ¼:
Bu deÄŸer gÃ¼ncellenme zse â†’ Bir sonraki Ã§alÄ±ÅŸmada TÃœM DOSYALAR tekrar indirilir
10,000 dosya Ã— her saat = Gereksiz network traffic, disk dolumu

1ï¸âƒ£4ï¸âƒ£ ConnectionFactory.disconnect()
Ne Yapar:
SFTP baÄŸlantÄ±sÄ±nÄ± kapatÄ±r, kaynaklarÄ± serbest bÄ±rakÄ±r

Cleanup Operations:
1. sftp.disconnect()     // SFTP session kapat
2. channel.disconnect()  // SSH channel kapat
3. socket.close()        // TCP socket kapat
4. Temp files temizle
5. Buffers'Ä± free et
6. Thread resources release

Log Summary:
log.info("Transfer completed: connection={}, files={}, totalSize={}, duration={}",
         connectionId, fileCount, totalSize, duration);

Output:
"Transfer completed: connection=1111, files=50, totalSize=750MB, duration=65s"

Finally Block:
try {
    // transfer operations
} finally {
    disconnect(); // â† ALWAYS EXECUTE (even if exception)
}

Neden Finally:
Exception olsa bile baÄŸlantÄ± mutlaka kapanmalÄ±
Yoksa: connection leak â†’ server'da aÃ§Ä±k socket'ler birikir

1ï¸âƒ£5ï¸âƒ£ handlerComplete()
Ne Yapar:
Handler'Ä±n iÅŸini bitirdiÄŸini Engine'e bildirir

Synchronization Mechanism:
CountDownLatch latch = new CountDownLatch(3); // 3 handler var

Handler-1 bitince: latch.countDown()  // 3 â†’ 2
Handler-2 bitince: latch.countDown()  // 2 â†’ 1
Handler-3 bitince: latch.countDown()  // 1 â†’ 0

Engine bekliyor:
latch.await()  // â† Block here until count = 0

Async Notification:
Handler â†’ Engine'e message gÃ¶nderir (non-blocking)
Handler devam etmez, thread sonlanÄ±r
Engine hala bekliyor (awaitHandlerCompletion'da)

Timeline:
10:00:00 - 3 handler baÅŸladÄ±
10:05:00 - Handler-1 bitti â†’ handlerComplete()
10:06:00 - Handler-2 bitti â†’ handlerComplete()
10:07:00 - Handler-3 bitti â†’ handlerComplete()  â† Count = 0
10:07:00 - Engine devam ediyor (decompress)

ğŸŸ¡ PHASE 3: Engine Post-processing
1ï¸âƒ£6ï¸âƒ£ awaitHandlerCompletion()
Ne Yapar:
TÃ¼m handler'larÄ±n bitmesini bekler (BLOCKING)

Code:
boolean completed = latch.await(1, TimeUnit.HOURS);
if (!completed) {
    log.warn("Timeout: Some handlers still running");
    // Proceed anyway
}

Timeline:
10:00:00 - Engine: await baÅŸladÄ± (BLOCKED)
10:07:00 - Handler-3 (son handler) bitti
10:07:00 - Engine: await sona erdi (UNBLOCKED) â†’ devam et

Timeout Scenario:
Default: 1 saat
EÄŸer handler 1 saatten fazla sÃ¼rerse â†’ Warning log, devam et

Result:
/raw/ klasÃ¶rÃ¼nde 150 dosya (3 handler Ã— 50 dosya)
Toplam: 2.2 GB compressed

1ï¸âƒ£7ï¸âƒ£ decompress()
Ne Yapar:
.gz ve .zip dosyalarÄ±nÄ± aÃ§ar (extract)

Thread Pool:
ExecutorService pool = Executors.newFixedThreadPool(8);
for (File gzFile : rawFiles) {
    pool.submit(() -> decompress(gzFile));
}

Decompression:
Input:  /raw/A20240708.0000+0300_eNodeB_001.xml.gz (15 MB)
Output: /processed/A20240708.0000+0300_eNodeB_001.xml (75 MB)

Expansion Rate: 5x (15MB â†’ 75MB)

Java Library:
GZIPInputStream gzis = new GZIPInputStream(new FileInputStream(gzFile));
// Read compressed â†’ Write decompressed

Performance:
Single thread: 10 MB/s
8 threads: 8 Ã— 10 = 80 MB/s

150 files Ã— 15MB = 2.2 GB
Decompression time: 2200 / 80 = 27.5 saniye

Error Handling:
Corrupt .gz file â†’ Log error, SKIP, devam et
(corrupt 1 dosya â†’ 149 dosya baÅŸarÄ±lÄ±)

1ï¸âƒ£8ï¸âƒ£ validation()
Ne Yapar:
XML dosyalarÄ±nÄ± XSD schema'ya gÃ¶re validate eder

XSD Schema (Vendor-specific):
Huawei: huawei_pm_schema.xsd
Ericsson: ericsson_pm_schema.xsd
Nokia: nokia_cm_schema.xsd

Validation Process:
SchemaFactory factory = SchemaFactory.newInstance(XMLConstants.W3C_XML_SCHEMA_NS_URI);
Schema schema = factory.newSchema(new File("huawei_pm_schema.xsd"));
Validator validator = schema.newValidator();

for (File xmlFile : processedFiles) {
    try {
        validator.validate(new StreamSource(xmlFile));
        // VALID âœ…
    } catch (SAXException e) {
        log.error("Invalid XML: {}", xmlFile);
        // INVALID âŒ â†’ Skip, continue
    }
}

Neden Gerekli:
Corrupt/malformed XML'leri Parser'a gÃ¶ndermemek
Parser crash'ini Ã¶nlemek
Data quality assurance

Performance:
Small XMLs (100KB): 1ms per file
1000 files/second Ã— 8 threads = 8000 files/second
150 files / 8000 = 0.02 saniye (instant)

Error Count:
149 valid, 1 invalid â†’ %99.3 success rate

1ï¸âƒ£9ï¸âƒ£ saveProcessHistory()
Ne Yapar:
Flow execution istatistiklerini database'e kaydeder

Generated Statistics:
{
  flow_process_code: "20240708100000000111",
  flow_id: 111,
  total_files: 150,
  success_count: 149,
  failure_count: 1,
  total_size_bytes: 2_200_000_000, // 2.2 GB
  execution_duration_ms: 420_000,   // 7 dakika
  start_time: "2024-07-08 10:00:00",
  end_time: "2024-07-08 10:07:00"
}

SQL Insert:
INSERT INTO t_transfer_process_history 
(flow_process_code, flow_id, total_files, success_count, failure_count,
 total_size_bytes, execution_duration_ms, start_time, end_time)
VALUES
('20240708100000000111', 111, 150, 149, 1, 2200000000, 420000,
 '2024-07-08 10:00:00', '2024-07-08 10:07:00')

Bu Data Ne Ä°ÅŸe Yarar:
- Performance monitoring dashboard
- Trend analysis (daily/weekly/monthly)
- SLA reporting (99% uptime)
- Capacity planning (disk, network)
- Debugging (slow runs, failures)

Grafana Dashboard:
Chart 1: Transfer duration trend (7 minutes average)
Chart 2: Success rate (99.3%)
Chart 3: Total data transferred (2.2 GB/hour)

2ï¸âƒ£0ï¸âƒ£ postEngine()
Ne Yapar:
Son iÅŸlemler: arÅŸivleme, bildirim, next module trigger

Operations:

1. Archive:
   Move /processed/*.xml â†’ /archive/
   Retention policy: 30 gÃ¼nlÃ¼k data, sonra sil
   
2. Reports:
   Generate summary report (PDF/Excel)
   Email to: ops-team@company.com
   Subject: "Transfer Report - 2024-07-08 10:00"
   
3. Notifications:
   If success_rate < 95% â†’ SMS alert to on-call engineer
   If failure â†’ PagerDuty incident
   
4. Trigger Parser:
   Send message to Kafka topic: "parser.input"
   Message: {files: 149, path: "/archive/20240708/"}
   Parser consumes â†’ Starts processing XMLs
   
5. Cleanup:
   Delete files older than 30 days
   Delete /raw/*.gz (already decompressed)
   Free disk space
   
6. Final Log:
   log.info("Transfer workflow completed successfully");

Integration Options:
- Kafka: Message queue for Parser
- RabbitMQ: Alternative message queue
- REST API: HTTP POST to Parser endpoint
- File watcher: Parser monitors /archive/ directory

ğŸ¯ Ã–zet: Complete Flow
10:00:00 â”€ START
       â”œâ”€ Load 3 connections from DB
       â”œâ”€ Create 3 handlers (parallel)
       â”‚
10:00:05 â”€ Handler-1: Connect to eNodeB_001
       â”œâ”€ List 10,000 files
       â”œâ”€ Filter â†’ 50 new files
       â”œâ”€ Download 50 Ã— 15MB = 750MB
       â”œâ”€ Save to DB (bulk insert)
       â”œâ”€ Disconnect
       â””â”€ Complete (5 minutes)
       
10:07:00 â”€ All handlers done
       â”œâ”€ Decompress: 150 files (30 seconds)
       â”œâ”€ Validate: 149 valid, 1 invalid (instant)
       â”œâ”€ Save stats to DB
       â””â”€ Trigger Parser
       
10:07:30 â”€ END SUCCESS